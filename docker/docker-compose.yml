version: '3.9'
services:
# spark
    spark:
        hostname: spark
        container_name: spark
        build:
            #path to docker files folder
            context: ./docker_files/spark
            #docker file name for spark in docker files folder
            dockerfile: dockerfile_spark
        volumes:
            #path to file share
            - ./file_share/spark/:/opt/spark-apps
            - ./file_share/spark/:/opt/spark-data
        ports:
            - '8080:8080'
        networks:
            - spark
        environment:
            - SPARK_MODE=master
            - SPARK_RPC_AUTHENTICATION_ENABLED=no
            - SPARK_RPC_ENCRYPTION_ENABLED=no
            - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
            - SPARK_SSL_ENABLED=no
            - SPARK_USER=spark

    spark_worker_a:
        hostname: spark_worker_a
        container_name: spark_worker_a
        build:
            #path to docker files folder
            context: ./docker_files/spark
            #docker file name for spark in docker files folder
            dockerfile: dockerfile_spark
        volumes:
            #path to file share
            - ./file_share/spark/:/opt/spark-apps
            - ./file_share/spark/:/opt/spark-data
        networks:
            - spark
        environment:
            - SPARK_MODE=worker
            - SPARK_MASTER_URL=spark://spark:7077
            - SPARK_WORKER_MEMORY=1G
            - SPARK_WORKER_CORES=1
            - SPARK_RPC_AUTHENTICATION_ENABLED=no
            - SPARK_RPC_ENCRYPTION_ENABLED=no
            - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
            - SPARK_SSL_ENABLED=no
            - SPARK_USER=spark
    spark_worker_b:
        hostname: spark_worker_b
        container_name: spark_worker_b
        build:
            #path to docker files folder
            context: ./docker_files/spark
            #docker file name for spark in docker files folder
            dockerfile: dockerfile_spark
        volumes:
            #path to file share
            - ./file_share/spark/:/opt/spark-apps
            - ./file_share/spark/:/opt/spark-data
        networks:
            - spark
        environment:
            - SPARK_MODE=worker
            - SPARK_MASTER_URL=spark://spark:7077
            - SPARK_WORKER_MEMORY=1G
            - SPARK_WORKER_CORES=1
            - SPARK_RPC_AUTHENTICATION_ENABLED=no
            - SPARK_RPC_ENCRYPTION_ENABLED=no
            - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
            - SPARK_SSL_ENABLED=no
            - SPARK_USER=spark
          
# python IDE in container
    jupyter:
        hostname: jupyter
        container_name: jupyter_container
        build:
            #path to docker files folder
            context: ./docker_files/jupyter
            #docker file name for jupyter in docker files folder
            dockerfile: dockerfile_jupyter
        volumes:
            #path to file share
            - ./file_share/jupyter_data/:/home/jovyan/
        ports:
            - '8888:8888'
        networks:
            - spark

    # DWH postgresSQL
    postgres:
        hostname: dwh_postgres
        container_name: dwh_postgres_container
        build:
            #path to docker files folder
            context: ./docker_files/dwh_postgresql
            #docker file name for dwh in docker files folder
            dockerfile: dockerfile_dwh_postgresql
        volumes:
            #path to file share
            - ./file_share/dwh_postgresql_data/:/var/lib/postgresql/data
        #set the DB name, user and password
        environment:
            POSTGRES_DB: 'dwh_postgres_db'
            POSTGRES_USER: 'dwh_postgres'
            POSTGRES_PASSWORD: 'dwh_postgres'
        ports:
            - '5432:5432'
        networks:
            - spark

    # pgadmin
    pgadmin:
        hostname: pgadmin
        container_name: pgadmin_container
        build:
            #path to docker files folder
            context: ./docker_files/pgadmin
            #docker file name for pgadmin in docker files folder
            dockerfile: dockerfile_pgadmin
        environment:
            PGADMIN_DEFAULT_EMAIL: "pgadmin@default.com"
            PGADMIN_DEFAULT_PASSWORD: "pgadminpswrd"
            PGADMIN_CONFIG_SERVER_MODE: "False"
        #path to file share
        volumes:
            - ./file_share/pgadmin_data/:/var/lib/pgadmin
        ports:
            - '5050:80'
        networks:
            - spark

networks:
  spark:
    driver: bridge